{"cells": [{"cell_type": "code", "execution_count": null, "id": "install-packages", "metadata": {}, "outputs": [], "source": ["!pip install transformers sentencepiece torch datasets"]}, {"cell_type": "code", "execution_count": null, "id": "import-libraries", "metadata": {}, "outputs": [], "source": ["from transformers import MarianMTModel, MarianTokenizer, Seq2SeqTrainingArguments, Seq2SeqTrainer\n", "from datasets import load_dataset, load_metric\n", "import torch"]}, {"cell_type": "code", "execution_count": null, "id": "load-model", "metadata": {}, "outputs": [], "source": ["# Load pre-trained model and tokenizer\n", "model_name = \"Helsinki-NLP/opus-mt-en-fr\"  # English to French\n", "tokenizer = MarianTokenizer.from_pretrained(model_name)\n", "model = MarianMTModel.from_pretrained(model_name)"]}, {"cell_type": "code", "execution_count": null, "id": "define-translation-function", "metadata": {}, "outputs": [], "source": ["def translate_sentence(sentence):\n", "    \"\"\"\n", "    Translates a given sentence using the pre-trained model.\n", "    \"\"\"\n", "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n", "    translated = model.generate(**inputs)\n", "    return tokenizer.decode(translated[0], skip_special_tokens=True)\n", "\n", "# Example Usage\n", "sentence = \"Hello, how are you?\"\n", "print(f\"Original: {sentence}\")\n", "print(f\"Translated: {translate_sentence(sentence)}\")"]}, {"cell_type": "code", "execution_count": null, "id": "load-dataset", "metadata": {}, "outputs": [], "source": ["# Load a dataset for training (Replace 'your_dataset.csv' with the actual dataset file)\n", "dataset = load_dataset('csv', data_files={'train': 'your_dataset.csv'})\n", "print(dataset)"]}, {"cell_type": "code", "execution_count": null, "id": "define-training-arguments", "metadata": {}, "outputs": [], "source": ["training_args = Seq2SeqTrainingArguments(\n", "    output_dir=\"./results\",\n", "    evaluation_strategy=\"epoch\",\n", "    learning_rate=5e-5,\n", "    per_device_train_batch_size=16,\n", "    per_device_eval_batch_size=16,\n", "    num_train_epochs=3,\n", "    save_total_limit=2,\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "define-trainer", "metadata": {}, "outputs": [], "source": ["trainer = Seq2SeqTrainer(\n", "    model=model,\n", "    args=training_args,\n", "    train_dataset=dataset['train'],\n", ")\n", "\n", "# Train the model\n", "trainer.train()"]}, {"cell_type": "code", "execution_count": null, "id": "evaluate-model", "metadata": {}, "outputs": [], "source": ["# Example Evaluation using BLEU score\n", "test_sentences = [\n", "    \"This is a test sentence.\",\n", "    \"Another sentence for translation.\",\n", "    \"How is the weather today?\",\n", "]\n", "\n", "references = [\n", "    [\"Ceci est une phrase de test.\"],\n", "    [\"Une autre phrase pour la traduction.\"],\n", "    [\"Quel temps fait-il aujourd'hui ?\"],\n", "]\n", "\n", "predictions = [translate_sentence(sentence) for sentence in test_sentences]\n", "metric = load_metric(\"bleu\")\n", "results = metric.compute(predictions=[[pred] for pred in predictions], references=references)\n", "print(f\"BLEU score: {results['bleu']}\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.10"}}, "nbformat": 4, "nbformat_minor": 4}